\section{Definitions}
% Abstract of the section
In this section we will introduce the notion of informativity. We will also look at the notation that will be used in the paper to indicate data and sets of systems. 

\subsection{Model classes}
We will start by defining model classes. When considering linear systems in state space form we know that they come in different forms. One of the more general forms is the following.

\begin{align}
	\mathbf{x}(t+1) &= A \mathbf{x}(t) + B \mathbf{u}(t) + \mathbf{w}(t)\\
	\mathbf{y}(t+1) &= C \mathbf{x}(t) + D \mathbf{u}(t)
\end{align}


Let us assume we have a system that has no input ($u$), output ($y$) or noise ($w$) variables and has a state space dimension of $3$. Then the system $\Sigma(A,B,C,D)$ can be described using only an $A$ matrix of size $3$. Intuitively this is a a very different type of system compared to a system that has a state space that is only $1$ dimension and does contain an input, output and noise variable. Hence we define a model class in the following way.

\Def{Model class}{
	A system $\Sigma_1$ is said to be the same model class as $\Sigma_2$ if the dimension of the state space, input space and output space are equivalent between both systems.
}

If we apply this to the previous example we can see that the 2 systems are not of the same model class because their state spaces have different dimensions.

\subsection{Informativity}
% Introducing the set of systems data informativity
Let $\Sigma$ be the set of discrete time models of a given model class and let $\mathcal{S}$ be a system from that model class. Then we know that $\mathcal{S}$ is contained in $\Sigma$. Lets say we want to infer a property from our system $\mathcal{S}$. Then if we show that the property holds for all systems in $\Sigma$ then it would also hold for $\mathcal{S}$. However, due to the size of $\Sigma$ this is not very feasible. Thus we need to reduce $\Sigma$ to a more manageable set. To do this we will use the data generated by $\mathcal{S}$. We will call this data $\mathcal{D}$. We will define the set of all systems of the given model class that are able to generate the data $\mathcal{D}$ by $\Sigma_\mathcal{D}$. By construction we know that $\mathcal{S} \in \Sigma_\mathcal{D} \subseteq \Sigma$.

Suppose we want to show if the true system is controllable, we might not be able to uniquely identify the true system using the data, i.e. $\# \Sigma_\mathcal{D} > 1$. However if we are able to show that every system in the set $\Sigma_\mathcal{D}$ is controllable, then we would also know that the true system is controllable. This is the idea behind data informativity. We say the data $\mathcal{D}$ is informative for a property $\mathcal{P}$ if all systems that describe the data $\Sigma_\mathcal{D}$ have the property $\mathcal{P}$. Let $\Sigma_\mathcal{P} \subseteq \Sigma$ be the set of all systems that have the property $\mathcal{P}$. Then we can reformulate the definition of data informativity as follows.

\Def{Informativity \cite[Def 1]{waarde2019data}}{
	We say that the data $\mathcal{D}$ is informative for a property $\mathcal{P}$ if $\Sigma_\mathcal{D} \subseteq \Sigma_\mathcal{P}$.
}

Suppose that the data describes only the true system, i.e. $\Sigma_{\mathcal{D}} = \{ \mathcal{S} \}$ then we know that if a property $\mathcal{P}$ hold for $\mathcal{S}$ then the data is informative for that property. However, in general, just because $\mathcal{S}$ has a property $\mathcal{P}$ does not immediately imply that the data is informative for $\mathcal{P}$ since the data might describe more then one system. Later on in section (\ref{ExampleOfSingleSystemHavingPropertyButNotInformative}) we will see this in an example where the data describes infinity many systems. 

We will also look at control problems. Suppose we want to see if the property '\textit{is stable in full state feedback with a controller $K$}' holds on the data, then we need to know if all systems are stabilisable by state feedback using the controller $K$. For this we will define the set of systems that are stabilised using state feedback for the controller $K$ as follows:
\[ \Sigma_K = \{ (A,B) \, | \, A + B \, K \mbox{ is stable} \} \]
Then we have that the data is informative if $\Sigma_\mathcal{D} \subseteq \Sigma_K$. We will generalise this using the following definition.

\Def{Informativity for control \cite[Def 3]{waarde2019data}}{
	We say that the data $\mathcal{D}$ is informative for a property $\mathcal{P}(\cdot)$ if there exists a controller $\mathcal{K}$ such that $\Sigma_\mathcal{D} \subseteq \Sigma_{\mathcal{P}(\mathcal{K})}$.
}


\subsection{Data}
% Introducing the notation for data
We will use the following example \cite[Ex 2]{waarde2019data} to give a more precise definition of data.

Lets consider systems from the model class of state space dimension $n$ and input space dimension $m$ without noise or output. Then we know that all systems contained in $\Sigma$ are of the form:
\begin{equation}
	\label{isSystem}
	\mathbf{x}(t+1) = A \mathbf{x}(t) + B \mathbf{u}(t)
\end{equation}
Where $\mathbf{x}(t)$ is the $n$-dimensional state vector and $\mathbf{u}(t)$ is the $m$-dimensional input vector evaluated at time $t$. We will pick a system from $\Sigma$ and call it our 'true' system. We will denote this system as $(A_s , B_s)$. 
We will use our true system to generate/measure the input and state data on $q$ time intervals $\{0,1,\dots,T_i\}$ where $i \in \{1,2,\dots,q\}$. We denote the data collected on one of these intervals as follows:
\begin{align*}
	U^{i}_{-} &= \left[ \begin{array}{cccc} u^{i}(0) & u^{i}(1) & \dots & u^{i}(T_i - 1) \end{array} \right] \\
	X^{i}     &= \left[ \begin{array}{cccc} x^{i}(0) & x^{i}(1) & \dots & x^{i}(T_i) \end{array} \right]
\end{align*}
We will now 'split' the state data into a 'past' and 'future' segment, these are defined similar to $U^i_-$.
\begin{align*}
	X^{i}_{-} &= \left[ \begin{array}{ccc} x^{i}(0) & \dots & x^{i}(T_i - 1) \end{array} \right] \\
	X^{i}_{+} &= \left[ \begin{array}{ccc} x^{i}(1) & \dots & x^{i}(T_i) \end{array} \right]
\end{align*}
With this representation of our state and input data we have that $X^{i}_{+} = A_s \, X^{i}_{-} + B_s \, U^{i}_{-}$. This holds for all measured intervals $i$ of the true system. We will now combine the data of all intervals to get a more general form.
\begin{align*}
	U_{-} &= \left[ \begin{array}{ccc} U^{1}_{-} & \dots & U^{q}_{-} \end{array} \right] &
	X     &= \left[ \begin{array}{ccc} X^{1} & \dots & X^{q} \end{array} \right] \\
	X_{+} &= \left[ \begin{array}{ccc} X^{1}_{+} & \dots & X^{q}_{+} \end{array} \right] &
	X_{-} &= \left[ \begin{array}{ccc} X^{1}_{-} & \dots & X^{q}_{-} \end{array} \right]
\end{align*}
We will define our data $\mathcal{D} := (U_-, X)$. In this example we have that $\Sigma_\mathcal{D} = \Sigma_{(U_-,X)} = \Sigma_{i/s}$ and is defined by:
\begin{equation} \label{isSet}
	\Sigma_{i/s} = \Sigma_{(U_-,X)} = \left\{ (A, B) \, | \, X_{+} = \begin{bmatrix} A & B \end{bmatrix} \begin{bmatrix} X_{-} \\ U_{-} \end{bmatrix} \right\}
\end{equation}

By construction we know that at least the true system $(A_s,B_s)$ is contained in this set.

We can extend this concept to also include the output of a system. Assume we have a system of the form:
\begin{subequations}\label{isoSystem}
	\begin{align}
		\mathbf{x}(t+1) &= A \mathbf{x}(t) + B \mathbf{u}(t) \\
		\mathbf{y}(t+1) &= C \mathbf{x}(t) + D \mathbf{u}(t)
	\end{align}
\end{subequations}

Let us define $Y_-$ in the following way:
\begin{align*}
	Y_-^i &= \begin{bmatrix}	y^i(0) & y^i(1)& \dots & y^i(T_i-1); \end{bmatrix}\\
	Y_- &= \begin{bmatrix} Y_-^1 & Y_-^2 & \dots & Y_-^q	\end{bmatrix}
\end{align*}
Then we can define the set of systems that can describe the data as follows:
\begin{equation}
\label{isoSet} 
\Sigma_{i/o/s} = 
\Sigma_{(U_-,X, Y_-)} = \left\{ (A, B, C, D) \, | \, 
\begin{bmatrix} X_{+} \\ Y_{-} \end{bmatrix} = 
\begin{bmatrix} A & B \\ C & D \end{bmatrix} 
\begin{bmatrix} X_{-} \\ U_{-} \end{bmatrix} \right\} 
\end{equation}

Lastly we will consider systems with bounded noise. These systems will be of the form:
\begin{align} \label{isnSystem}
	\mathbf{x}(t+1) &= A \mathbf{x}(t) + B \mathbf{u}(t) + \mathbf{y}(t)
\end{align}
For these systems we will only use a single measurement interval. Hence we will define our noise data $W_-$ as follows.
\[ W_- = \begin{bmatrix} w(0) & w(1) & \dots & w(T-1)	\end{bmatrix} \]
Note that $W_-$ is unknown, we only have access to our state and input data generated by these systems. Later, in section (\ref{sectionNoise}) we will go into more detail on how we can define the bound on the noise as a matrix inequality and how we can use this for control.









