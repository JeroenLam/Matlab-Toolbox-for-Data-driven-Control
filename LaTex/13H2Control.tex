\section{H$_2$ Control}
% Abstract section


% What is H2
\Def{Informative for $\mathcal{H}_2$ control \cite[Def 15]{waarde2020noisy}}{
	the data $(U_-,X)$ is informative for $\mathcal{H}_2$ control with performance $\gamma$ if there exists matrices $p = p^\top > 0$ and $K$ such that:
	\begin{align*}
		P &> (A + BK)^\top P (A + BK) + (C + DK)^\top(C+DK) & 
		trace(P) &< \gamma^2
	\end{align*}
	holds for all $(A,B) \in \Sigma_{i/s/n}$.
}

% Mathematics


% Proof?


% State theorem
\Thr{\cite[Thr 16]{waarde2020noisy}}{
	Assume that the generalised Slater condition (\ref{GenerelisedSlaterCondition}) holds for $N$ in (\ref{NData}) and some $\bar{Z} \in \mathbb{R}^{(n+m_ \times n)}$. Then the data $(U_-,X)$ is informative for $\mathcal{H}_2$ control with performance $\gamma$ if and only if there exists matrices $Y = Y^\top > 0$, $Z = Z^\top$ and $L$, and scalars $\alpha \geq 0$ and $\beta>0$ satisfying:
	\begin{equation*}
		\begin{bmatrix}
			Y - \beta I & 0 & 0 & 0 & 0 \\
			0 & 0 & 0 & Y & 0 \\
			0 & 0 & 0 & L & 0 \\
			0 & Y & L^\top & Y & (CY + DL)^\top \\
			0 & 0 & 0 & CY + DL & I 
		\end{bmatrix} - \alpha
		\begin{bmatrix} I&X_+ \\ 0 & -X_- \\ 0&-U_- \\ 0&0 \\ 0&0 \end{bmatrix}
		\begin{bmatrix} \Phi_{11} & \Phi_{12} \\ \Phi_{12}^\top & \Phi_{22} \end{bmatrix}
		\begin{bmatrix} I&X_+ \\ 0 & -X_- \\ 0&-U_- \\ 0&0 \\ 0&0 \end{bmatrix}^\top \geq 0
	\end{equation*}
	\begin{align*}
		\begin{bmatrix} Y & (CY + DL)^\top \\ CY + DL & I \end{bmatrix} &> 0 &
		\begin{bmatrix} Z & I \\ I & Y \end{bmatrix} &\geq 0 &
		trace(Z) &< \gamma^2
 	\end{align*}
	Moreover, if $Y$ and $L$ satisfy the above conditions, then $K = LY^{-1}$ is such that $A + BK$ is stable and $\| G(z)\|_{\mathcal{H}_2} < \gamma$ for all $(A,B) \in \Sigma$. \todo{Explain G(z)}
}

% Pseudo code / algorithm
\subsection{Implementation}
\subsubsection*{Syntax} 
\mon{[bool, K, diagnostics, gamma, info] = isInformH2(X, U, Phi, C, D)} \\
\mon{[bool, K, diagnostics, gamma, info] = isInformH2(X, U, Phi, C, D, tolerance)} \\
\mon{[bool, K, diagnostics, gamma, info] = isInformH2(X, U, Phi, C, D, tolerance, options)} 

\subsubsection*{Description} \todo{a}
\mon{[bool, K, diagnostics, gamma, info] = isInformH2(X, U, Phi, C, D)}: . \\
\mon{[bool, K, diagnostics, gamma, info] = isInformH2(X, U, Phi, C, D, tolerance)}: . \\
\mon{[bool, K, diagnostics, gamma, info] = isInformH2(X, U, Phi, C, D, tolerance, options)}: .

\subsubsection*{Input arguments}
\textbf{\mon{X}}: State data matrix of dimension $n \times T+1$ from a input/state data set.\\
\textbf{\mon{U}}: Input data matrix of dimension $m \times T$ from a input/state data set.\\
\textbf{\mon{Phi}}: Noise matrix as in (\ref{noiseBound}). \\ 
\textbf{\mon{C}}: State performance matrix. \\ 
\textbf{\mon{D}}: State performance matrix. \\ 
\textbf{\mon{tolerance}}: Tolerance used for determining when a value is zero up to machine precision. Default value is \mon{1e-14}.\\
\textbf{\mon{options}}: sdpsettings used with the Yalmip solver.

\subsubsection*{Output arguments}
\textbf{\mon{bool}}: (boolean) True if the data is informative for quadratic stabilisation, false otherwise. If false then the \mon{info} variable can be check to find which condition failed. \\
\textbf{\mon{K}}: (matrix) If the data is informative, it contains a stabilising controller \mon{K} for closed loop control \mon{A+BK}, empty otherwise.\\
\textbf{\mon{diagnostics}}: (struct) Diagnostics from the Yalmip \mon{optimize()} function. \\
\textbf{\mon{gamma}}: (double) Value of gamma as found by the solver. \\
\textbf{\mon{info}}: (int) Diagnostic variable use to identify which conditions (if any) failed. The verification is done on the solution obtained from Yalmip. For information about the type of error use the \mon{help} command in Matlab


% Example using function
\subsection{Example}
In this example we will consider the same data that we used in the quadratic stabilisation example.
\begin{align*}
	x(t+1) &= 2x(t) - \frac{1}{2}u(t) + w(t) \\
	W_- &= \begin{bmatrix}  0.0706 &  0.0244 & -0.0298 & 0.0026 & -0.0196 \end{bmatrix} \\
	U_- &= \begin{bmatrix} -0.1655 & -0.9007 &  0.8054 & 0.8896 & -0.0183 \end{bmatrix} \\
	X   &= \begin{bmatrix}     0   &  0.1533 &  0.6281 & 0.1956 & -0.2466 & -0.2571 \end{bmatrix} \\
\end{align*}
As we saw in that example we can use the following $\Phi$ as a valid noise bound.
\begin{equation*}
\Phi = \begin{bmatrix} 0.05 & \overline{0} \\ \overline{0}^\top & -I_9 \end{bmatrix}
\end{equation*}
We also know that the generalised Slater condition holds. At this point we only need to find a $Y = Y^\top > 0$, $Z = Z^\top$, $L$, $\alpha$ and $\beta$ such that the following inequalities hold.
\begin{equation*}
\begin{bmatrix}
Y - \beta I & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & Y & 0 \\
0 & 0 & 0 & L & 0 \\
0 & Y & L^\top & Y & (CY + DL)^\top \\
0 & 0 & 0 & CY + DL & I 
\end{bmatrix} - \alpha
\begin{bmatrix} I&X_+ \\ 0 & -X_- \\ 0&-U_- \\ 0&0 \\ 0&0 \end{bmatrix}
\begin{bmatrix} \Phi_{11} & \Phi_{12} \\ \Phi_{12}^\top & \Phi_{22} \end{bmatrix}
\begin{bmatrix} I&X_+ \\ 0 & -X_- \\ 0&-U_- \\ 0&0 \\ 0&0 \end{bmatrix}^\top \geq 0
\end{equation*}
\begin{align*}
\begin{bmatrix} Y & (CY + DL)^\top \\ CY + DL & I \end{bmatrix} &> 0 &
\begin{bmatrix} Z & I \\ I & Y \end{bmatrix} &\geq 0 &
trace(Z) &< \gamma^2
\end{align*}
Using numerical tools like Yalmip we are able to find that the following values form a valid solution.
\begin{align*}
	Y &= 3.578190407584625 \\
	Z &= 0.279470874690682 \\
	L &= 6.860884484332921 \\
	a &= 80.398493367163880 \\
	b &= 1.162504055224782e-06
\end{align*}
With a performance of $\gamma = 0.528650049362224$ and a feedback gain $K = 1.917417382202476$.
\todo{Check what the best gamma is}


We are also able to find a stabilising feedback gain using the provided Matlab function.
\begin{lstlisting}
C = 0.5;
D = 0;
U = [-0.1655 -0.9007 0.8054 0.8896 -0.0183];
X = [ 0       0.1533 0.6281 0.1956 -0.2466 -0.2571];
Phi = [0.05 zeros(1,5) ; zeros(5,1) -eye(5)];
[bool, K] = isInformH2(X, U, Phi, C, D)
\end{lstlisting}
Which will return: \mon{[ 1, 1.917417382202475 ]}.